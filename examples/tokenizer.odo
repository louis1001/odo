enum TokenType {
    Num,
    Id,
    Plus,
    Minus,
    Aster,
    Slash,
    Lpare,
    Rpare,
    Eof
}

class Token {
    TokenType type
    string name
    init(TokenType tp, string m) {
        type = tp
        name = m
    }

    func to_string() {
        return "Token(" + type + ", '" + name + "')"
    }
}

class Lexer {
    string text = ""
    int current_pos = 0

    init(string txt) {
        text = txt
    }

    func advance() {
        current_pos++
    }

    func current_char(): string {
        if current_pos >= length(text) {
            return ""
        }

        return text[current_pos]
    }

    func ignore_whitespace() {
        while current_char() != "" && isWhitespace(current_char()) {
            advance()
        }
    }

    func number(): string {
        string result = current_char()

        advance()
        while isAlphaNum(current_char()) {
            result += current_char()
            advance()
        }

        return result
    }

    func id() {
        string result = current_char()
        advance()

        while isAlphaNum(current_char()) {
            result += current_char()
            advance()
        }

        return result
    }

    func get_next_token(): Token {
        ignore_whitespace()
        if current_pos >= length(text) {
            return new Token(TokenType::Eof, "")
        }

        if isNumber(current_char()) {
            return new Token(TokenType::Num, number())
        }

        if current_char() == "+" {
            advance()
            return new Token(TokenType::Plus, "+")
        } else if current_char() == "-" {
            advance()
            return new Token(TokenType::Minus, "-")
        } else if current_char() == "*" {
            advance()
            return new Token(TokenType::Aster, "*")
        } else if current_char() == "/" {
            advance()
            return new Token(TokenType::Slash, "/")
        } else if current_char() == "(" {
            advance()
            return new Token(TokenType::Lpare, "(")
        } else if current_char() == ")" {
            advance()
            return new Token(TokenType::Rpare, ")")
        } else if isAlpha(current_char(), true) {
            return new Token(TokenType::Id, id())
        }

        println("Error! Unknown character '", current_char(), "'.")
    }
}

string numbers = "0123456789"
string alpha = "abcdefghijklmnopqrstuvwxyz"

func isSomething (string val, string lst) {
    for (int i = 0; i < length(lst); i++) {
        if val == lst[i] {
            return true
        }
    }

    return false
}

func isNumber(string char): bool {
    return isSomething(char, numbers)
}

func isAlpha(string char, bool check_undescore = false) {
    if check_undescore {
        return isSomething(char, alpha) || char == "_"
    }

    return isSomething(char, alpha)
}

func isAlphaNum(string char) {
    return isNumber(char) || isAlpha(char, true)
}

func isWhitespace(string char) {
    return isSomething(char, " \n\t\r")
}

func tokenize(string text) {

    int current_pos = 0

    Lexer lx = new Lexer(text)

    Token current_token = lx.get_next_token()
    while current_token.type != TokenType::Eof {
        println(current_token.to_string())

        current_token = lx.get_next_token()
    }
}

string code = "pi * (100/20) - 10 * 29 / x"

string user_code = read("> ")
if user_code != "" {
    code = user_code
}

println("The tokens in ", code)
tokenize(code)